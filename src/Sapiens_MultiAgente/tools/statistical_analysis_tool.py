import pandas as pd
import numpy as np
from scipy import stats
from typing import Type, Optional, Dict, Any, List
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import json


class StatisticalAnalysisToolInput(BaseModel):
    """Input schema for StatisticalAnalysisTool."""
    data: str = Field(..., description="JSON string containing the data to analyze")
    analysis_type: str = Field(..., description="Type of analysis: descriptive, correlation, hypothesis_test, regression")
    variables: Optional[List[str]] = Field(default=None, description="Variables to analyze")
    alpha: float = Field(default=0.05, description="Significance level for hypothesis tests")


class StatisticalAnalysisTool(BaseTool):
    name: str = "StatisticalAnalysisTool"
    description: str = (
        "Ferramenta avan√ßada para an√°lises estat√≠sticas. Realiza an√°lises descritivas, "
        "correla√ß√µes, testes de hip√≥teses, regress√µes e outras an√°lises estat√≠sticas "
        "para apoiar decis√µes baseadas em dados acad√™micos."
    )
    args_schema: Type[BaseModel] = StatisticalAnalysisToolInput

    def _run(self, data: str, analysis_type: str, variables: Optional[List[str]] = None, alpha: float = 0.05) -> str:
        """
        Executa an√°lise estat√≠stica nos dados fornecidos.

        Args:
            data: Dados em formato JSON
            analysis_type: Tipo de an√°lise desejada
            variables: Vari√°veis espec√≠ficas para an√°lise
            alpha: N√≠vel de signific√¢ncia

        Returns:
            Resultados da an√°lise estat√≠stica
        """
        try:
            # Parse dos dados
            data_dict = json.loads(data)

            # Converter para DataFrame se necess√°rio
            if isinstance(data_dict, list):
                df = pd.DataFrame(data_dict)
            elif isinstance(data_dict, dict):
                # Assumir que √© um dict com chaves como colunas
                df = pd.DataFrame(data_dict)
            else:
                return "‚ùå ERRO: Formato de dados n√£o suportado."

            if df.empty:
                return "‚ùå ERRO: Dados vazios fornecidos."

            # Selecionar vari√°veis se especificadas
            if variables:
                available_vars = [v for v in variables if v in df.columns]
                if not available_vars:
                    return f"‚ùå ERRO: Nenhuma das vari√°veis especificadas encontrada: {variables}"
                df = df[available_vars]

            # Executar an√°lise baseada no tipo
            if analysis_type.lower() == "descriptive":
                return self._descriptive_analysis(df)
            elif analysis_type.lower() == "correlation":
                return self._correlation_analysis(df)
            elif analysis_type.lower() == "hypothesis_test":
                return self._hypothesis_testing(df, alpha)
            elif analysis_type.lower() == "regression":
                return self._regression_analysis(df)
            else:
                return f"‚ùå ERRO: Tipo de an√°lise n√£o suportado: {analysis_type}"

        except json.JSONDecodeError:
            return "‚ùå ERRO: Dados n√£o est√£o em formato JSON v√°lido."
        except Exception as e:
            return f"‚ùå ERRO durante an√°lise estat√≠stica: {str(e)}"

    def _descriptive_analysis(self, df: pd.DataFrame) -> str:
        """An√°lise descritiva completa."""
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns

        report = "üìä AN√ÅLISE DESCRITIVA\n\n"

        if len(numeric_cols) > 0:
            report += "üìà VARI√ÅVEIS NUM√âRICAS:\n"
            desc_stats = df[numeric_cols].describe(percentiles=[.25, .5, .75, .9, .95]).round(3)
            report += desc_stats.to_string() + "\n\n"

            # Teste de normalidade (Shapiro-Wilk)
            report += "üîî TESTE DE NORMALIDADE (Shapiro-Wilk):\n"
            for col in numeric_cols:
                try:
                    stat, p_value = stats.shapiro(df[col].dropna())
                    normality = "Normal" if p_value > 0.05 else "N√£o normal"
                    report += f"‚Ä¢ {col}: {normality} (p={p_value:.3f})\n"
                except:
                    report += f"‚Ä¢ {col}: N√£o foi poss√≠vel testar\n"
            report += "\n"

        if len(categorical_cols) > 0:
            report += "üìä VARI√ÅVEIS CATEG√ìRICAS:\n"
            for col in categorical_cols:
                value_counts = df[col].value_counts()
                report += f"‚Ä¢ {col}:\n{value_counts.to_string()}\n\n"

        return report

    def _correlation_analysis(self, df: pd.DataFrame) -> str:
        """An√°lise de correla√ß√£o."""
        numeric_cols = df.select_dtypes(include=[np.number]).columns

        if len(numeric_cols) < 2:
            return "‚ùå ERRO: Necess√°rio pelo menos 2 vari√°veis num√©ricas para an√°lise de correla√ß√£o."

        # Matriz de correla√ß√£o de Pearson
        corr_matrix = df[numeric_cols].corr(method='pearson').round(3)

        report = "üîó AN√ÅLISE DE CORRELA√á√ÉO\n\n"
        report += "üìä MATRIZ DE CORRELA√á√ÉO (Pearson):\n"
        report += corr_matrix.to_string() + "\n\n"

        # Correla√ß√µes significativas
        report += "üéØ CORRELA√á√ïES SIGNIFICATIVAS (|r| > 0.5):\n"
        significant_corr = []

        for i in range(len(numeric_cols)):
            for j in range(i+1, len(numeric_cols)):
                corr = corr_matrix.iloc[i, j]
                if abs(corr) > 0.5:
                    strength = self._interpret_correlation_strength(corr)
                    significant_corr.append(f"‚Ä¢ {numeric_cols[i]} ‚Üî {numeric_cols[j]}: r = {corr} ({strength})")

        if significant_corr:
            report += "\n".join(significant_corr)
        else:
            report += "Nenhuma correla√ß√£o forte detectada."

        return report

    def _hypothesis_testing(self, df: pd.DataFrame, alpha: float) -> str:
        """Testes de hip√≥teses."""
        numeric_cols = df.select_dtypes(include=[np.number]).columns

        if len(numeric_cols) < 2:
            return "‚ùå ERRO: Necess√°rio pelo menos 2 vari√°veis num√©ricas para testes de hip√≥teses."

        report = f"üß™ TESTES DE HIP√ìTESES (Œ± = {alpha})\n\n"

        # Testes t para m√©dias
        if len(numeric_cols) >= 2:
            report += "üìè TESTES T PARA DIFEREN√áA DE M√âDIAS:\n"
            for i in range(len(numeric_cols)):
                for j in range(i+1, len(numeric_cols)):
                    try:
                        var1, var2 = numeric_cols[i], numeric_cols[j]
                        data1 = df[var1].dropna()
                        data2 = df[var2].dropna()

                        if len(data1) > 0 and len(data2) > 0:
                            # Teste t independente
                            t_stat, p_value = stats.ttest_ind(data1, data2, equal_var=False)
                            significant = "Sim" if p_value < alpha else "N√£o"
                            report += f"‚Ä¢ {var1} vs {var2}: t={t_stat:.3f}, p={p_value:.3f} (significativo: {significant})\n"
                    except Exception as e:
                        report += f"‚Ä¢ Erro em {numeric_cols[i]} vs {numeric_cols[j]}: {str(e)}\n"

        return report

    def _regression_analysis(self, df: pd.DataFrame) -> str:
        """An√°lise de regress√£o linear simples."""
        numeric_cols = df.select_dtypes(include=[np.number]).columns

        if len(numeric_cols) < 2:
            return "‚ùå ERRO: Necess√°rio pelo menos 2 vari√°veis num√©ricas para regress√£o."

        report = "üìà AN√ÅLISE DE REGRESS√ÉO LINEAR\n\n"

        # Regress√£o simples entre primeira e segunda vari√°vel num√©rica
        x_col, y_col = numeric_cols[0], numeric_cols[1]

        try:
            # Remover valores faltantes
            clean_data = df[[x_col, y_col]].dropna()

            if len(clean_data) < 3:
                return "‚ùå ERRO: Dados insuficientes para regress√£o (m√≠nimo 3 pontos)."

            X = clean_data[x_col].values.reshape(-1, 1)
            y = clean_data[y_col].values

            # Regress√£o linear
            from sklearn.linear_model import LinearRegression
            from sklearn.metrics import r2_score, mean_squared_error

            model = LinearRegression()
            model.fit(X, y)

            y_pred = model.predict(X)
            r2 = r2_score(y, y_pred)
            mse = mean_squared_error(y, y_pred)
            slope = model.coef_[0]
            intercept = model.intercept_

            report += f"üìä Regress√£o: {y_col} = {slope:.3f} √ó {x_col} + {intercept:.3f}\n"
            report += f"üìà R¬≤ = {r2:.3f} (coeficiente de determina√ß√£o)\n"
            report += f"üìè MSE = {mse:.3f} (erro quadr√°tico m√©dio)\n"

            # Interpreta√ß√£o
            if r2 > 0.8:
                interpretation = "Excelente ajuste"
            elif r2 > 0.6:
                interpretation = "Bom ajuste"
            elif r2 > 0.3:
                interpretation = "Ajuste moderado"
            else:
                interpretation = "Ajuste fraco"

            report += f"üí° Interpreta√ß√£o: {interpretation}\n"

        except Exception as e:
            report += f"‚ùå Erro na regress√£o: {str(e)}\n"

        return report

    def _interpret_correlation_strength(self, corr: float) -> str:
        """Interpreta a for√ßa da correla√ß√£o."""
        abs_corr = abs(corr)
        if abs_corr >= 0.9:
            return "Correla√ß√£o muito forte"
        elif abs_corr >= 0.7:
            return "Correla√ß√£o forte"
        elif abs_corr >= 0.5:
            return "Correla√ß√£o moderada"
        elif abs_corr >= 0.3:
            return "Correla√ß√£o fraca"
        else:
            return "Correla√ß√£o muito fraca"